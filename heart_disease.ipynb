{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6339049a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a35c965",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c1b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import *\n",
    "\n",
    "data = load_data(DatasetDirectory.HEART_DISEASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513feee",
   "metadata": {},
   "source": [
    "## 2. Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4822d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing(data, DatasetDirectory.HEART_DISEASE)\n",
    "feature_train, label_train, feature_test, label_test = prepare_dataset_v2(data, train_ratio=0.8, test_ratio=0.2,\n",
    "                                                                          dataset_directory=DatasetDirectory.HEART_DISEASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd53e8",
   "metadata": {},
   "source": [
    "## 3. Build the decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66674dc9",
   "metadata": {},
   "source": [
    "### 3.1 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdee838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0]\n",
      "Actual labels: [0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42, max_depth=4)\n",
    "\n",
    "clf.fit(feature_train, label_train)\n",
    "\n",
    "label_pred = clf.predict(feature_test)\n",
    "print(\"Predicted labels:\", label_pred)\n",
    "print(\"Actual labels:\", label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f9f3b",
   "metadata": {},
   "source": [
    "### 3.2 Visualize the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4745f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "# from sklearn import tree\n",
    "# import os\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "#                                  feature_names=[str(i) for i in range(feature_train.shape[1])],\n",
    "#                                     class_names=[str(i) for i in np.unique(label_train)],\n",
    "#                                     filled=True, rounded=True,\n",
    "#                                     special_characters=True)\n",
    "\n",
    "# graph = graphviz.Source(dot_data)\n",
    "# directory = os.getcwd()\n",
    "# graph.render(filename=os.path.join(directory, 'heart_disease_tree'), format='png', cleanup=True)\n",
    "# print(\"Decision tree visualization saved as 'heart_disease_tree.png'\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, \n",
    "          feature_names=[str(i) for i in range(feature_train.shape[1])],\n",
    "          class_names=[str(i) for i in np.unique(label_train)],\n",
    "          filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ca3bd",
   "metadata": {},
   "source": [
    "## 4. Evaluating the decision tree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f4953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.83        36\n",
      "           1       0.76      0.67      0.71        24\n",
      "\n",
      "    accuracy                           0.78        60\n",
      "   macro avg       0.78      0.76      0.77        60\n",
      "weighted avg       0.78      0.78      0.78        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31  5]\n",
      " [ 8 16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(label_test, label_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(label_test, label_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(label_test, label_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
